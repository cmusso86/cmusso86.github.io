---
title: "Integração R e Python"
---

# Machine Learning com scikit-learn no R

<!-- https://quarto.org/docs/presentations/revealjs/ -->

<!-- https://github.com/rstudio/revealjs -->

<!-- https://quarto.org/docs/presentations/ -->

<!-- https://beatrizmilz.github.io/python-brasil-2021-reticulate -->

## Scikit-learn

![](https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Scikit_learn_logo_small.svg/1200px-Scikit_learn_logo_small.svg.png){fig-align="center" width="336"}

-   Popular biblioteca de machine learning para Python;

-   Vasto conjunto de algoritmos para processamento de dados e construção de modelos;

-   Consistente, eficiente e de fácil utilização;

-   Excelente documentação, repleta de exemplos e tutoriais.

## Ferramentas do scikit-learn

## Pré-processamento

-   Seleção, transformação, criação de variáveis;

-   Codificação de dados categorizados nominais e ordinais;

-   Redução de dimensionalidade (PCA, FA etc.);

-   Imputação de dados faltantes;

-   Manipulação de dados em texto.

-   etc.

## Modelos

-   **Regressão:** linear, ridge, LASSO, SVR etc;
-   **Classificação:** regressão logística, árvore de decisão, SVM, naive Bayes, LDA/QDA etc;
-   **Clusterização:** K-Means, misturas gaussianas etc;
-   **Outros:**
    -   Estimação de densidades de probabilidade;

    -   Decomposição de sinais;

    -   Detecção de anomalias;

    -   Redes neurais.

## Avaliação e seleção de modelos

-   Particionamento dos dados em treino-teste;

-   Métricas gerais de performance;

-   Estimação de hiperparâmetros;

-   Validação cruzada.

## Integrando o scikit-learn ao R

## Preparação

-   O primeiro passo é carregar o pacote `reticulate` e indicar onde serão executados os códigos Python; nesse caso, no ambiente virtual "venv".

::: fragment
```{r include=FALSE, eval=TRUE, output=FALSE}
library(reticulate)
if (!require(pacman)) install.packages("pacman")
pacman::p_load(tidyverse, reticulate, rio , glue)

pacotes<-read.table("requirements.txt") %>% 
  select(V1) %>% 
  pull()



pacotes<-pacotes[-33]
patoes<-pacotes[c(35,20)]

virtualenv_create("venv")
use_virtualenv("venv")
virtualenv_install("venv",patoes)
virtualenv_install("venv","seaborn")
```
:::

::: fragment
```{r include=TRUE, eval=FALSE, warnings=FALSE}
library(reticulate)
use_virtualenv("venv2", required=TRUE)
```
:::

-   Caso precise criar esse ambiente virtual, primeiro execute:

::: fragment
```{r eval=FALSE}
# use_python("C:/Users/user/anaconda3")
# virtualenv_create("venv",
#                   packages=c("scikit-learn",
#                              "numpy", "pandas"))
```
:::

## Ex: classificação de tumores de mama

```{r include=FALSE, eval=TRUE, output=FALSE}
library(readr)
breast_cancer <- read_csv("breast_cancer.csv")
```

```{r include=TRUE, eval=TRUE, output=FALSE}
library(readr)
breast_cancer <- read_csv("breast_cancer.csv")
```

```{r}
head(breast_cancer, 4)
```

-   O objetivo é identificar se um tumor é maligno (câncer de mama) ou benigno.

## 

No scikit-learn, para ajustar um modelo é preciso separar covariáveis, representadas pela data frame `X`, e variável resposta `y`.

::: fragment
```{r warning=FALSE}
library(dplyr)
X <- dplyr::select(breast_cancer, -y)
y <- dplyr::select(breast_cancer, y) # 0 = maligno, 1 = benigno
```
:::

## Divisão em treino e teste

-   No contexto de machine learning, é rotineiro separar uma parte dos dados para testar a capacidade de um modelo, geralmente, 20% das observações. Isso pode ser feito do seguinte modo no sklearn:

::: fragment
```{r}
model_sel <- reticulate::import("sklearn.model_selection")

py_set_seed(42)
split <- model_sel$train_test_split(X, y, test_size=0.20)

X_train <- split[[1]]; X_test <- split[[2]]
y_train <- split[[3]]; y_test <- split[[4]]
```
:::

> A função `py_set_seed` fixa a semente dos geradores de números aleatórios do Python para a reprodução de resultados.

## O modelo de classificação

-   Um possível modelo consiste na padronização das variáveis, seguida da retenção dos cinco componentes principais de maior variação e sobre eles um Support Vector Machine.

::: fragment
```{r}
pipe <- reticulate::import("sklearn.pipeline")
preproc <- reticulate::import("sklearn.preprocessing")
decomp <- reticulate::import("sklearn.decomposition")
svm <- reticulate::import("sklearn.svm")

model <- pipe$make_pipeline(
  preproc$StandardScaler(),         # Padronização
  decomp$PCA(n_components=5L),      # Componentes principais
  svm$LinearSVC(C=8.71, dual=FALSE) # Support Vector Machine
)
```
:::

## O modelo de classificação

::: fragment
```{r echo=T, eval=F}

model <- pipe$make_pipeline(
  preproc$StandardScaler(),         # Padronização
  decomp$PCA(n_components=5L),      # Componentes principais
  svm$LinearSVC(C=8.71, dual=FALSE) # Support Vector Machine
)
```
:::

-   O **pipeline** é análogo ao pipe `%>%` do R:
    -   Sequência de transformações, seguida de um modelo;

    -   Unifica/simplifica as etapas de pré-processamento, estimação e ajuste de hiperparâmetros, e previsões.

## Ajuste do modelo

-   <div>

    > Os hiperparâmetros `n_components` e `C` definidos podem ser ajustados utilizando métodos de [validação cruzada](https://scikit-learn.org/stable/modules/cross_validation.html) (Grid Search, Random Search etc.) sobre o pipeline.

    </div>

-   Com os hiperparâmetros definidos, ajusta-se o modelo aos dados de **treino**.

::: fragment
```{r warning=FALSE, output=FALSE}
model$fit(X_train, y_train)
```
:::

-   <div>

    > **(Vazamento de dados)**. O pipeline ajuda a reforçar o uso de apenas os dados de **treino** para o ajuste.

    </div>

## Performance do modelo

-   Agora, a verificação da qualidade das previsões por meio da acurácia no conjunto de **teste**.

::: fragment
```{r}
metrics <- reticulate::import("sklearn.metrics")
y_pred_test <- model$predict(X_test)

metrics$accuracy_score(y_test, y_pred_test)
```
:::

-   <div>

    > O scikit-learn dispõe de outras [métricas](https://scikit-learn.org/stable/modules/classes.html?highlight=metrics#classification-metrics) de performance para modelos de classificação, tais como: acurácia balanceada, precisão, recall, F1 etc.

    </div>

## 

-   Como estamos num ambiente R, podemos usar de forma natural o `ggplot2` e fazer uma comparação gráfica entre o que foi observado e as previsões.

::: fragment
```{r eval=FALSE}
test_data <- X_test
test_data["y"] <- y_test
test_data["y_pred"] <- y_pred_test

library(ggplot2)
ggplot(test_data)+
  geom_jitter(aes(x=y_pred,y=y ))


```
:::

## 

```{r, echo=F, eval=F}
knitr::include_graphics("capitulos/scikit-learn/graf.png")
```

```{r, echo=F, out.width="70%"}
test_data <- X_test
test_data["y"] <- y_test
test_data["y_pred"] <- y_pred_test

library(ggplot2)
ggplot(test_data)+
  geom_jitter(aes(x=y_pred,y=y ))
  

```

# Materiais

1.  Para mais informações sobre a biblioteca scikit-learn, veja sua [página na web](https://scikit-learn.org/stable/getting_started.html) e o [guia de usuário](https://scikit-learn.org/stable/user_guide.html);

2.  [Como Usar Pipelines no Scikit-Learn - João Paulo Nogueira](https://medium.com/data-hackers/como-usar-pipelines-no-scikit-learn-1398a4cc6ae9);

3.  [Cross Validation - scikit-learn](https://scikit-learn.org/stable/modules/cross_validation.html);

4.  [GÉRON, Aurélien (2019)](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/). Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow;

5.  [Translating between tidymodels and scikit-learn - Kelly Bodwin](https://www.kelly-bodwin.com/talks/rsconf22/).
