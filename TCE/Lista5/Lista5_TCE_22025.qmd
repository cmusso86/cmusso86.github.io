---
title: "Lista 5"
subtitle: "Reamostragem"
author: 
  Carolina Musso
  251103768
date: today
institute: "Mestrado Acadêmico em Estatística - UnB"
lang: pt
format: 
  html:
    toc: true
    toc-location: left
    toc-depth: 2
    number-sections: true
    self-contained: true
    embed-resources: true
editor: source
execute:
  echo: true
  message: false
  warning: false
---

# Exercício

Considere o conjunto de dados de ar condicionado (`aircondit`) disponível no pacote boot do R. São 12 observações dos tempos (em horas) entre falhas do equipamento de ar condicionado:

```{r}
pacman::p_load(boot,
               alr4 , 
               tidyverse,
               geomtextpath)
air <- c(3, 5, 7, 18, 43, 85, 91, 98, 100, 130, 230, 487)
```

Suponha que os tempos entre falhas sigam um modelo exponencial $Exp(\lambda)$. Calcule intervalos de confiança de bootstrap de 95% para o tempo médio entre falhas $1/\lambda$ pelos métodos normal, básico, percentil e BCa. Considere o estimador de máxima verossimilhança $\hat{\lambda}$ para o problema.


### Solução
```{r}
medias <- numeric()
R <- 100000 # A quantidade de reamostragens

set.seed(123) # Para reprodutibilidade
for (i in 1:R) {
  amostra <- sample(air, replace = TRUE)
  medias[i] <- mean(amostra)
}

media_original <- mean(air)
```

Com as reamostragens por bootstrap, conseguimos ter uma noção da distribuição amostral da estatística de interesse. Nesse caso, o estimador de máxima verosiimilhança será a própria média amostral.  

Ao calcular esse estimador para cada amostra de bootstrap, temos agora uma amostra de estimadores. Com isso, podemos fazer um gráfico de densidade, como abaixo. Vemos que a distribuição se aproxima da normal, mas aparece ser mais assimétrica à direita, o que é esperado, já que veio de uma distribuição exponencial.

```{r}
plot(density(medias))
```


### Intevalo de confiança Normal

Nesse caso, podemos usar a média e o desvio padrão da distribuição amostral para calcular o intervalo de confiança baseado em uma normal padrão, considerando que a média amostral é aproximadamente normal segundo o Teorema Central do Limite.


```{r}
LI <- media_original + qnorm(0.025) * sd(medias) 
LS <- media_original- qnorm(0.025) * sd(medias) 
cat("Intervalo de confiança normal: (", LI, ",", LS, ")\n")
```

Comparando com o pacote `boot`, podemos usar a função `boot.ci` para calcular o intervalo de confiança baseado na normal. Obtemos valores semelhantes, mas com uma pequena diferença pelo fato de ser um processo aleatório.  

```{r}
# funcao de media com indice 
fun <- function(x, i) {
  mean(x[i])
}

boot_out <- boot(air, fun, R)
CI1 <- boot.ci(boot_out,  seed = 123, type = "norm")
CI1$normal[-1]

```

Entretanto, sabemos que nessa situação, a aproximação da normal pode não ser boa, já vimos que temos uma distribuição assimétrica acima. Para verificar isso, podemos fazer o teste de Shapiro-Wilk e o gráfico QQ-plot, que mostram desvios da normalidade. 


```{r}
# testar se o vetor medias é normal

shapiro.test(sample(medias, 500))
qqnorm(sample(medias, 500))
```


### Intervalo de confiança básico

Nesse caso, o intervalo de confiança básico é dado por:

```{r}
2*media_original - quantile(medias, probs = c(0.975, 0.025))

```

Comparando com o pacote boot, podemos usar a função `boot.ci` para calcular o intervalo de confiança básico. 
```{r}
CI2 <- boot.ci(boot_out,  seed = 123, type = "basic")
CI2$basic[-c(1:3)]
```

### Intervalo percentil

Nesse caso, o intervalo de confiança percentil é dado pelo percentil diretamente da distribuição empírica.


```{r}
quantile(medias, probs = c(0.025, 0.975))
```

Comparando com o pacote boot, podemos usar a função `boot.ci` para calcular o intervalo de confiança percentil. 

```{r}
CI3 <- boot.ci(boot_out,  seed = 123, type = "perc")
CI3$percent[-c(1:3)]
```


### Intervalo BCa

Esse intervalo é um pouco mais complicado de calcular, pois é um método que corrige a assimetria e a viés da distribuição amostral. Ele usa o método de Jackknife para calcular a correção e fornece um intevalo mais robusto.

Adaptando o exemplo das notas de aulas,temos:


```{r}

boot.BCa <- 
    function(x, th0, th, stat, conf = .95) {
      
        n <- length(x) #observations in rows
        alpha <- (1 + c(-conf, conf))/2
        zalpha <- qnorm(alpha)
        z0 <- qnorm(sum(th < th0) / length(th))
        th.jack <- numeric(n)
        for (i in 1:n) { 
          th.jack[i] <- stat(x[-i ])
          }
        L <- mean(th.jack) - th.jack
        a <- sum(L^3)/(6 * sum(L^2)^1.5)
        adj.alpha <- pnorm(z0 + (z0+zalpha)/(1-a*(z0+zalpha)))
        limits <- quantile(th, adj.alpha, type=6)
        return(list( "BCa"=limits))
    }


boot.BCa(air, 
         th0 = media_original, 
         th = medias, 
         stat = mean)

```
Vemos que o intervalo BCa é mais robusto e leva em consideração a assimetria da distribuição amostral. Novamente, podemos usar o pacote `boot` para calcular o intervalo BCa de forma mais simples, e obtemos valores semelhantes.

```{r}
# Intervalo de confiança BCa com boot

CI4 <- boot.ci(boot_out,  seed = 123, type = "bca")
CI4$bca[-c(1:3)]
```

```{r}
# Comparando os intervalos de confiança em um grafico


IC1 <- CI1$normal[-1]
IC2 <- CI2$basic[-c(1:3)]
IC3 <- CI3$percent[-c(1:3)]
IC4 <- CI4$bca[-c(1:3)]

dados <- data.frame(
  r = 1:R,
  medias = medias
)

library(ggplot2)
library(dplyr)

# Crie data.frames para cada par de limites com nome e cor
ic_data <- data.frame(
  x = c(IC1[1], IC1[2], IC2[1], IC2[2], IC3[1], IC3[2], IC4[1], IC4[2]),
  tipo = factor(rep(c("Percentil", "Normal", "BCa", "Basic"), each = 2),
                levels = c("Percentil", "Normal", "BCa", "Basic"))
)

media_data <- data.frame(
  x = media_original,
  tipo = "Média original"
)


ggplot(dados, aes(x = medias)) +
  geom_density() +
  geom_vline(data = media_data, aes(xintercept = x, color = tipo), linetype = "dashed") +
  geom_vline(data = ic_data, aes(xintercept = x, color = tipo), linetype = "dashed") +
  scale_color_manual(values = c(
    "Média original" = "red",
    "Percentil" = "blue",
    "Normal" = "green",
    "BCa" = "purple",
    "Basic" = "orange"
  )) +
  labs(
    title = "Intervalos de Confiança para a Média",
    x = "Média Amostral",
    y = "Densidade",
    color = "Tipo de Intervalo"
  ) +
  theme_minimal()



  

```


# Exercício

 Considere novamnete os dados sobre consumo de combustível nos 50 estados + DC dos Estados Unidos (Federal Highway Administration, 2001). Os dados foram coletados pela Federal Highway Administration dos EUA; ver Weisberg, S. (2014). Applied Linear Regression. John Wiley & Sons, Hoboken, New Jersey, fourth edition.
 
 Temos as seguintes variáveis:

**Drivers:** Número de motoristas com carteira de habilitação no estado.
**FuelC:** Gasolina vendida para uso rodoviário, milhares de galões.
**Income:** Renda pessoal por pessoa no ano 2000 em dólares.
**Miles:** Milhas de rodovias com ajuda federal no estado.
**Pop:** População de 2001 com 16 anos ou mais.
**Tax:** Taxa de imposto estadual da gasolina, centavos por galão.
**MPC:** Milhas estimadas percorridas per capita.

Considere ainda as variáveis:

**Fuel:** 1000 × FuelC/Pop.
**Dlic:** 1000 × Drivers/Pop.
**lMiles:** Logaritmo natural de Miles.

Podemos tentar entender como o combustível (Fuel) está relacionado aos preditores (Tax, Dlic, Income e Miles), usando um modelo de regressão linear múltipla.

```{r}
######################################
## Código R
######################################

data(fuel2001)
fuel2001$lMiles <- log(fuel2001$Miles) 
fuel2001$Dlic   <- 1000*(fuel2001$Drivers/fuel2001$Pop)
fuel2001$Fuel   <- 1000*(fuel2001$FuelC/fuel2001$Pop)
fuel2001$Income <- fuel2001$Income/1000
```

Problema: Considere os seguintes modelos:

$Fuel = \beta_0 + \beta1Tax + \epsilon$

$Fuel = \beta_0 + \beta1Tax + \beta_2Dlic + \epsilon$

$Fuel = \beta_0 + \beta1Tax + \beta_2Dlic + \beta_3Income + \epsilon$

$Fuel = \beta_0 + \beta1Tax + \beta_2Dlic + \beta_3Income + \beta_4lMiles + \epsilon$

Use o procedimento leave-one-out para estimar os erros das predições e escolher o melhor dos modelos acima. Como critérios, use o RMSE e MAE, dados por:

$$RMSE = \sqrt{\frac{1}{n}\sum_{t=1}^n(y_t-\hat{y_t})^2}\\MAE= \frac{1}{n}\sum_{t=1}^n{|y_t-\hat{y_t}|}$$
```{r}

# Inicializar erros
n <- nrow(fuel2001)
e1 <- e2 <- e3 <- e4 <- numeric(n)

# Leave-one-out
for (k in 1:n) {
  train <- fuel2001[-k, ]
  test  <- fuel2001[k, ]

  # Modelo 1
  m1 <- lm(Fuel ~ Tax, data = train)
  yhat1 <- predict(m1, newdata = test)
  e1[k] <- test$Fuel - yhat1

  # Modelo 2
  m2 <- lm(Fuel ~ Tax + Dlic, data = train)
  yhat2 <- predict(m2, newdata = test)
  e2[k] <- test$Fuel - yhat2

  # Modelo 3
  m3 <- lm(Fuel ~ Tax + Dlic + Income, data = train)
  yhat3 <- predict(m3, newdata = test)
  e3[k] <- test$Fuel - yhat3

  # Modelo 4
  m4 <- lm(Fuel ~ Tax + Dlic + Income + lMiles, data = train)
  yhat4 <- predict(m4, newdata = test)
  e4[k] <- test$Fuel - yhat4
}

# Cálculo dos critérios
rmse <- function(e) sqrt(mean(e^2))
mae  <- function(e) mean(abs(e))

# Comparação dos modelos
data.frame(
  Modelo = paste("Modelo", 1:4),
  RMSE = c(rmse(e1), rmse(e2), rmse(e3), rmse(e4)),
  MAE  = c(mae(e1), mae(e2), mae(e3), mae(e4))
)

```


Segundo esses critérios, o modelo 4 é o melhor, pois apresenta os menores valores de RMSE e MAE. Isso indica que ele tem um desempenho superior na previsão do consumo de combustível em comparação com os outros modelos.     


